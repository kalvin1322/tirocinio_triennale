# CT Reconstruction Training & Benchmarking CLI

A user-friendly command-line tool for training, testing, and benchmarking CT reconstruction models with **multi-experiment support**.

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
conda env create -f environment.yml
conda activate tirocinio
```


### 2. Launch Interactive Mode (Recommended)

```bash
python run.py interactive
```

### 3. Create Your First Experiment

When you launch interactive mode, you'll see:
- ğŸ”¬ **Create/Select Experiment** - Start here!

Select this option to:
1. Create a new experiment (gets a dedicated folder)
2. Or select an existing experiment to continue working on it

Each experiment gets its own organized folder structure:
```
experiments/
â””â”€â”€ your_experiment_name/
    â”œâ”€â”€ experiment_config.yaml    # Experiment configuration
    â”œâ”€â”€ trained_models/           # Your trained models
    â”œâ”€â”€ test_results/             # Test outputs
    â”œâ”€â”€ benchmarks/               # Benchmark results
    â””â”€â”€ logs/                     # Training logs
```

### 4. Start Training/Testing

Once you've created/selected an experiment:
- ğŸš€ **Train a new model** - Train preprocessing + postprocessing pipelines
- ğŸ§ª **Test an existing model** - Evaluate your models
- ğŸ“Š **Benchmark multiple models** - Compare different combinations

## ğŸ“– Usage Modes

### Interactive Mode (Recommended for Beginners) ğŸŒŸ

Guided step-by-step interface with full experiment management:

```bash
python run.py interactive
```

**Main Menu Features:**
- ğŸ”¬ **Create/Select Experiment** - Manage multiple experiments
- ğŸš€ **Train a new model** - Train preprocessing + postprocessing pipelines
- ğŸ§ª **Test an existing model** - Evaluate trained models with visualization
- ğŸ“Š **Benchmark multiple models** - Compare different combinations

### Command-Line Mode (For Automation & HPC) ğŸš€

Direct commands for scripts, batch jobs, and SLURM:

```bash
# Create experiment
python run.py create-experiment --name my_experiment --train-dataset "data/Mayo_s Dataset/train" --test-dataset "data/Mayo_s Dataset/test"

# Train model
python run.py train --experiment my_experiment --postprocessing UNet_V1 --epochs 50 --batch-size 8

# Test with visualization
python run.py test --experiment my_experiment --checkpoint FBP_UNet_V1.pth --visualize --num-samples 10

# Benchmark multiple models
python run.py benchmark --experiment my_experiment --postprocessing UNet_V1,ThreeL_SSNet
```

**Perfect for:**
- ğŸ–¥ï¸ **HPC clusters** (Open OnDemand, SLURM)
- ğŸ“œ **Automated scripts** and pipelines
- ğŸ”„ **Batch processing** multiple experiments
- ğŸ“Š **Hyperparameter sweeps**

ğŸ“– **Full CLI documentation with examples**: [CLI_USAGE.md](docs/CLI_USAGE.md)


## ğŸ“ Project Structure

```
tirocinio/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/                      # CLI interface
â”‚   â”‚   â”œâ”€â”€ main.py               # Main entry point
â”‚   â”‚   â”œâ”€â”€ interactive.py        # Interactive menus
â”‚   â”‚   â”œâ”€â”€ commands.py           # Command implementations
â”‚   â”‚   â””â”€â”€ wizard.py             # Experiment creation wizard
â”‚   â”œâ”€â”€ models/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ UNet_V1.py            # U-Net model
â”‚   â”‚   â””â”€â”€ ThreeL_SSNet.py       # ThreeL-SSNet model
â”‚   â”œâ”€â”€ dataloader/               # Dataset loaders
â”‚   â”‚   â””â”€â”€ CTDataloader.py       # CT dataset with FBP
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â”œâ”€â”€ geometry_config.py    # Projection geometry loader
â”‚       â”œâ”€â”€ models_config.py      # Model configuration loader
â”‚       â””â”€â”€ train_test.py         # Training/testing functions
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ projection_geometry.json  # CT geometry configurations
â”‚   â””â”€â”€ models_config.json        # Model pipeline configurations
â”œâ”€â”€ experiments/                  # Experiment outputs (created on first use)
â”‚   â”œâ”€â”€ experiments_index.yaml    # Index of all experiments
â”‚   â””â”€â”€ experiment_name/          # Individual experiment folder
â”‚       â”œâ”€â”€ experiment_config.yaml
â”‚       â”œâ”€â”€ trained_models/
â”‚       â”œâ”€â”€ test_results/
â”‚       â”œâ”€â”€ benchmarks/
â”‚       â””â”€â”€ logs/
â”œâ”€â”€ Mayo_s Dataset/              # Your CT dataset
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ run.py                       # Quick launcher
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ docs/                        # Documentation
    â”œâ”€â”€ CLI_USAGE.md             # CLI commands & HPC guide
    â”œâ”€â”€ MODEL_CONFIGURATION.md   # Model config system guide
    â””â”€â”€ EXPERIMENTS_SYSTEM.md    # Experiments guide
```

## ğŸ’¡ Tips

1. **Always Create an Experiment First** - All operations require an active experiment
2. **Use Descriptive Names** - Name experiments clearly (e.g., `fbp_unet_comparison`)
3. **Multiple Experiments** - Run different experiments in parallel without conflicts
4. **Use GPU** - Training is much faster with CUDA
5. **Benchmark Combinations** - Test multiple preprocessing+postprocessing combinations at once
6. **Edit JSON Configs** - Add new models without touching code (see `configs/models_config.json`)

## ğŸ”§ Configuration Files

### Experiment Configuration (Auto-generated)

Each experiment gets its own `experiment_config.yaml`:

```yaml
experiment:
  name: my_experiment
  description: Testing UNet vs ThreeL_SSNet
  created_at: 2025-10-30T14:30:22.123456
  
datasets:
  train: Mayo_s Dataset/train
  test: Mayo_s Dataset/test
  train_samples: 3305
  test_samples: 327
  
output_dirs:
  base: experiments/my_experiment
  models: experiments/my_experiment/trained_models
  results: experiments/my_experiment/test_results
  benchmarks: experiments/my_experiment/benchmarks
```

### Model Configuration (User-editable)

#### Model Definitions (`models_config.json`)

Edit `configs/models_config.json` to add new models:

```json
{
  "preprocessing": {
    "FBP": {
      "name": "Filtered Back Projection",
      "description": "Standard FBP reconstruction algorithm",
      "filters": ["ram-lak", "shepp-logan", "cosine", "hamming", "hann"],
      "default_filter": "ram-lak"
    }
  },
  "postprocessing": {
    "UNet_V1": {
      "name": "U-Net V1",
      "description": "U-Net architecture with skip connections for high-quality reconstruction",
      "class": "UNet_V1",
      "in_channels": 1,
      "out_channels": 1
    },
    "ThreeL_SSNet": {
      "name": "Three-Level Squeeze-and-Excitation Network",
      "description": "Lightweight three-level squeeze-and-excitation network for fast enhancement",
      "class": "ThreeL_SSNet"
    }
  }
}
```

#### Model Parameters (`model_parameters.json`)

Customize **postprocessing model** hyperparameters in `configs/model_parameters.json`:

```json
{
  "UNet_V1": {
    "description": "U-Net architecture with customizable encoder-decoder pairs",
    "default_params": {
      "in_channels": 1,
      "out_channels": 1,
      "num_encoders": 3,
      "start_middle_channels": 64
    },
    "tunable_params": {
      "num_encoders": {
        "type": "int",
        "min": 2,
        "max": 5,
        "default": 3,
        "description": "Number of encoder-decoder pairs"
      },
      "start_middle_channels": {
        "type": "int",
        "options": [32, 64, 128, 256],
        "default": 64,
        "description": "Starting number of middle channels"
      }
    }
  }
}
```

**Benefits:**
- ğŸ¯ Centralized parameter management
- âœ… Automatic validation (min/max, allowed values)
- ğŸ“ Self-documenting configuration
- ğŸ”§ Easy to add new tunable parameters
- ğŸ“› Automatic model naming with parameters

**Postprocessing Model Examples (CLI configurable):**
```bash
# Default parameters
python run.py train --postprocessing UNet_V1 --epochs 50
# Output: FBP_UNet_V1_ep50_lr0001.pth

# Custom UNet architecture
python run.py train --postprocessing UNet_V1 --num-encoders 4 --start-channels 128
# Output: FBP_UNet_V1_ep50_lr0001.pth

# Custom SimpleResNet
python run.py train --postprocessing SimpleResNet --num-layers 3 --features 16
# Output: FBP_SimpleResNet_ep50_lr0001.pth
```

âš ï¸ **Important**: **Preprocessing parameters** (e.g., SART/SIRT iterations) are **NOT configurable via CLI**.  
They must be set in `configs/models_config.json` before training. See [Model Configuration Guide](docs/MODEL_CONFIGURATION.md) for details.

## ğŸ“š Additional Documentation

- **[CLI Usage Guide](docs/CLI_USAGE.md)** - Complete command-line reference for automation and HPC
- **[Model Configuration Guide](docs/MODEL_CONFIGURATION.md)** - How to add/configure models
- **[Experiments System Guide](docs/EXPERIMENTS_SYSTEM.md)** - Complete guide to the experiments system
- **[projection_geometry_guide](docs/projection_geometry_guide.md)** - Guide for CT machine configuratio
- **[Adding Pre-processing method](docs/ADDING_PREPROCESSING_METHODS.md)** -  Guide to add pre-processing methods
- **[Adding Custom Dataset](data/README.md)** - Guide to add custom dataset
- **[Adding Custom Refining Method](docs/REFINING_GUIDE.md) - Guide to add custom refining method

